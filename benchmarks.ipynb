{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25773d87",
   "metadata": {},
   "source": [
    "Note that the first run for a date range will include downloading and preprocessing global VIIRS data for that date range. \n",
    "\n",
    "Also note that the first run for a region in a date range will include preprocessing files for that region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireatlas.FireRunDaskCoordinator import Run_local\n",
    "from fireatlas.FireTypes import Region, TimeStep\n",
    "import datetime as dt\n",
    "import os\n",
    "import subprocess\n",
    "import cProfile\n",
    "import traceback\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_feds_with_logging(region: Region, tst: TimeStep, ted: TimeStep):\n",
    "    \n",
    "    from fireatlas import settings \n",
    "\n",
    "    run_start_time = dt.datetime.now()\n",
    "    # start_timestamp = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    os.makedirs(\"benchmark_logs\", exist_ok=True)\n",
    "    log_file = \"./benchmark_logs/run_log.csv\"\n",
    "\n",
    "    run = 0\n",
    "    \n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, newline=\"\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                if region[0] in row[\"region\"]:\n",
    "                    run += 1\n",
    "\n",
    "    run_name = f\"{region[0]}_run{run}\"\n",
    "    profile_stats_filename = f\"{run_name}.prof\"\n",
    "\n",
    "\n",
    "    log = {\n",
    "        \"run_name\": run_name,\n",
    "        \"run_start_time\": run_start_time.isoformat(),\n",
    "        \"run_end_time\": \"\", \n",
    "        \"duration_seconds\": \"\",\n",
    "        \"region\": region,\n",
    "        \"tst\": tst,\n",
    "        \"ted\": ted, \n",
    "        \"git_branch\": \"\", \n",
    "        \"git_commit_hash\": \"\", \n",
    "        \"FIRE_SOURCE\": settings.FIRE_SOURCE, \n",
    "        \"N_DASK_WORKERS\": settings.N_DASK_WORKERS,\n",
    "        \"FTYP_OPT\": settings.FTYP_OPT, \n",
    "        \"run_completed\": False, \n",
    "        \"error\": \"\",\n",
    "        \"profile_file\": profile_stats_filename\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        log[\"git_branch\"] = subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"],stderr=subprocess.DEVNULL, text=True).strip()\n",
    "        log[\"git_commit_hash\"] = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"],stderr=subprocess.DEVNULL, text=True).strip()\n",
    "    except: \n",
    "        # if this doesnt work, whatever\n",
    "        pass \n",
    "\n",
    "    profiler = cProfile.Profile()\n",
    "\n",
    "    try:\n",
    "        profiler.enable()\n",
    "        _ = Run_local(region, tst, ted)\n",
    "        profiler.disable()\n",
    "        log[\"run_completed\"] = True\n",
    "    except Exception:\n",
    "        profiler.disable()\n",
    "        log[\"error\"] = traceback.format_exc()\n",
    "    \n",
    "    run_end_time = dt.datetime.now()\n",
    "    log[\"run_end_time\"] = run_end_time.isoformat()\n",
    "    log[\"duration_seconds\"] = (run_end_time - run_start_time).total_seconds()\n",
    "\n",
    "    os.makedirs(\"benchmark_profiles\", exist_ok=True)\n",
    "    profiler.dump_stats(f\"./benchmark_profiles/{profile_stats_filename}\")\n",
    "    \n",
    "    csv_file = \"benchmark_logs/run_log.csv\"\n",
    "    exists = os.path.exists(csv_file)\n",
    "    with open(csv_file, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, log.keys())\n",
    "        if not exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(log)\n",
    "    \n",
    "    print(f\"[run_with_logging] Run logged to {csv_file}\")\n",
    "    print(f\"[run_with_logging] Profile saved to {profile_stats_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f74f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# careful! clears all local FEDS outputs\n",
    "!rm -r ./data/FEDSoutput-v3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one region \n",
    "# region = [\"North_America\", \"North_America.geojson\"]\n",
    "# tst = [2024, 1, 1, \"AM\"]\n",
    "# ted = [2024, 1, 2, \"AM\"]\n",
    "\n",
    "# Run_local(region, tst, ted) # make sure it runs in general, without logging \n",
    "# run_feds_with_logging(region, tst, ted) # test on one region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67727df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one day for each region with logging \n",
    "# took 7 minutes for first run of jan 1-2 \n",
    "\n",
    "regions = [\"Africa\",\n",
    "           \"Australia_New_Zealand\",\n",
    "           \"Caribbean\",\n",
    "           \"Central_Asia\",\n",
    "           \"Europe_W_Siberia\",\n",
    "           \"India\", \n",
    "           \"Japan_Far_East\",\n",
    "           \"North_America\",\n",
    "           \"SE_Asia\", \n",
    "           \"Seven_Seas\", \n",
    "           \"Siberia\", \n",
    "           \"South_America\"]\n",
    "\n",
    "for r in regions:\n",
    "    region = [r, r+\".geojson\"]\n",
    "    tst = [2024, 1, 1, \"AM\"]\n",
    "    ted = [2024, 1, 2, \"AM\"]\n",
    "    run_feds_with_logging(region, tst, ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14216d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./benchmark_logs/run_log.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add profiling to each run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40faa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one month for each region with logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up monthly (?) checkpointing script for long runs "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
